{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b396465b",
   "metadata": {},
   "source": [
    "## Analysis of data\n",
    "The data set provided contains 2000 positive IMDB review & the 2000 negative IMDB reviews. Each .txt file is labelled with an index and the number rating given.\n",
    "\n",
    "Going through the reviews briefly here are the things that I identified:\n",
    "1) The reviews seem to vary in length and there isn't a maximum amount of characters enforced\n",
    "\n",
    "2) Some reviews contains <br /><br /> within their text\n",
    "\n",
    "3) Some movie's (based on id) have negative and positive reviews like id=15\n",
    "\n",
    "4) Several reviewers written sentimental opinions has many instances of sarcasm\n",
    "\n",
    "5) All the reviews are in English\n",
    "\n",
    "6) There seem to be no spelling errors\n",
    "\n",
    "7) Words like \"Gen-X/Y-ers\" where it is cobbled up by the reviewer are used\n",
    "\n",
    "8) Some but not all put the rating within the review (e.g: 4/10 or 4 of 10)\n",
    "\n",
    "9) Grammar of sentences seem correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307992f5",
   "metadata": {},
   "source": [
    "## Analysis of task\n",
    "\n",
    "Sentiment analysis essentially revolves around identifying and extracting subjective information from text. Determining the overall sentiment of a document or piece of text. Sentiment analysis is often used to classify the sentiment of types of user-generated content, to understand the public opinion about a particular topic or product. This can aid businesses to have better data analysis and allow them to make better informed decisions.\n",
    "\n",
    "Sentiment analysis as a machine learning problem contains several chanllenges. One of these challenges pertains the subjectivty of language. Sentiment is often expressed in subtle ways, people often use irony, sarcasm, and other forms of figurative speech which isn't easy for machine to identify/understand.\n",
    "\n",
    "First thoughts of machine learning may have issues with:\n",
    "1) Sarcasm and irony are used within negative reviews when reviewers vent their frustration.\n",
    "\n",
    "2) Phrases such as good \"bad\" (15_1.txt) are used which may affect word associations to sentiments.\n",
    "\n",
    "3) Words may be misinterpreted like \"sad\", the movie could be a sad story but is a good film and have a positive review which may be classified wrongly if using word associations to sentiment. While for a negative review (413_3.txt) \"Just sad.\" is written to display their dissapointment within a negative sentiment. The contradictions is shown.\n",
    "\n",
    "4) Reviews vary in length which may effect the term frequencies.\n",
    "\n",
    "These issues are strongly correlated with the feature vectors we choose (e.g, length, term frequency, word associtaion,...). More detail will be discussed pertaining the different feature vectors chosen and the specific issues that come with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b11544",
   "metadata": {},
   "source": [
    "## Reading .txt files and processing them into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a904526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_documents(string):\n",
    "    f = open(string) # if accessed locally\n",
    "    merged = \"\"\n",
    "    text=f.read()\n",
    "    text=text.replace(\"<br />\", \"\")\n",
    "    text=text.strip()\n",
    "    f.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93799713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 4000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "all_data=[]\n",
    "file_names=[]\n",
    "senti=[\"pos\",\"neg\"]\n",
    "current_directory = os.getcwd()\n",
    "for sen in senti:\n",
    "    #change path to txt files if required here\n",
    "    path = \"/Users/simonlim/Library/CloudStorage/OneDrive-UniversityofBath/NLP/Assignment/data/\"+sen\n",
    "    os.chdir(path)\n",
    "    for count,file in enumerate(os.listdir()):\n",
    "            file_path = path+\"/\"+file\n",
    "          # Pre-processing  file_names.append(file)\n",
    "            \n",
    "            if sen == \"pos\":\n",
    "                all_data.append((read_documents(file_path),\"positive\"))\n",
    "            else:\n",
    "                all_data.append((read_documents(file_path),\"negative\"))\n",
    "\n",
    "print(\"Number of reviews: {}\".format(len(all_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a44982",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d6a9ed",
   "metadata": {},
   "source": [
    "Preparing raw text data for further analysis through cleaning and normalizing text, tokenizing the text into individual words or phrases, removing punctuation and stop words, and stemming or lemmatizing the words to reduce them to their base form can help improve the performance and accuracy of our sentiment analysis . Pre-processing can remove noise and inconsistencies that can interfere with the analysis, and by tokenizing and lemmatizing the words, it can possibly make it easier for the model to identify and analyze the individual components of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5429f53f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonlim/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/simonlim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/simonlim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/simonlim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/simonlim/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "#removed the stopwords, lemmatize and stematized words as well the text of a document \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ngrams\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "lm = WordNetLemmatizer()\n",
    "st= LancasterStemmer()\n",
    "stoplist = set(stopwords.words('english'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93827d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##For Naive Bayes\n",
    "def get_features_label(text,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt):\n",
    "    features = {}\n",
    "    terms = {}\n",
    "    if doNothing:\n",
    "        words=text.split(\" \")\n",
    "    elif doLemma:\n",
    "        words=get_features_lemma(text,doTokenize,doStopWords,doPuncFilt)\n",
    "    elif doStemma:\n",
    "        words=get_features_stemma(text,doTokenize,doStopWords,doPuncFilt)\n",
    "    elif doTokenize:\n",
    "        tokenized=word_tokenize(text)\n",
    "        lowered = [w.lower() for w in tokenized]\n",
    "        if doStopWords:\n",
    "            if doPuncFilt:\n",
    "                words = [word for word in lowered if word not in stoplist and word.isalpha()]\n",
    "            else:\n",
    "                words = [word for word in lowered if word not in stoplist]\n",
    "        else:\n",
    "            if doPuncFilt:\n",
    "                words = [word  for word in lowered if  word.isalpha()]\n",
    "            else:\n",
    "                words = [word  for word in lowered]\n",
    "    elif doTokenize==False:\n",
    "        split = text.split(\" \")\n",
    "        lowered = [w.lower() for w in split]\n",
    "        if doStopWords:\n",
    "            if doPuncFilt:\n",
    "                words = [word for word in lowered if word not in stoplist and word.isalpha()]\n",
    "            else:\n",
    "                words = [word for word in lowered if word not in stoplist]\n",
    "        else:\n",
    "            if doPuncFilt:\n",
    "                words = [word for word in lowered if word.isalpha()]\n",
    "            else:\n",
    "                words = [word for word in lowered]\n",
    "                \n",
    "    for word in words:\n",
    "        features[word] = True\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_features_stemma(text,doTokenize,doStopWords,doPuncFilt): \n",
    "    if doTokenize:\n",
    "        tokenized=word_tokenize(text)\n",
    "        lowered = [w.lower() for w in tokenized]\n",
    "        if doStopWords:\n",
    "            if doPuncFilt:\n",
    "                word_list = [st.stem(word) for word in lowered if word not in stoplist and word.isalpha()]\n",
    "            else:\n",
    "                word_list = [st.stem(word) for word in lowered if word not in stoplist]\n",
    "        else:\n",
    "            if doPuncFilt:\n",
    "                word_list = [st.stem(word) for word in lowered if word.isalpha()]\n",
    "            else:\n",
    "                word_list = [st.stem(word) for word in lowered]\n",
    "                \n",
    "    elif doTokenize==False:\n",
    "        split = text.split(\" \")\n",
    "        lowered = [w.lower() for w in split]\n",
    "        if doStopWords:\n",
    "            if doPuncFilt:\n",
    "                word_list = [st.stem(word) for word in lowered if word not in stoplist and word.isalpha()]\n",
    "            else:\n",
    "                word_list = [st.stem(word) for word in lowered if word not in stoplist]\n",
    "        else:\n",
    "            if doPuncFilt:\n",
    "                word_list = [st.stem(word) for word in lowered if word.isalpha()]\n",
    "            else:\n",
    "                word_list = [st.stem(word) for word in lowered]\n",
    "    sentences=word_list\n",
    "    return sentences\n",
    "\n",
    "def get_features_lemma(text,doTokenize,doStopWords,doPuncFilt): \n",
    "    if doTokenize:\n",
    "        tokenized=word_tokenize(text)\n",
    "        lowered = [w.lower() for w in tokenized]\n",
    "        if doStopWords:\n",
    "            if doPuncFilt:\n",
    "                word_list = [lm.lemmatize(word) for word in lowered if word not in stoplist and word.isalpha()]\n",
    "            else:\n",
    "                word_list = [lm.lemmatize(word) for word in lowered if word not in stoplist]\n",
    "        else:\n",
    "            if doPuncFilt:\n",
    "                word_list = [lm.lemmatize(word) for word in lowered if word.isalpha()]\n",
    "            else:\n",
    "                word_list = [lm.lemmatize(word) for word in lowered ]\n",
    "                \n",
    "    elif doTokenize==False:\n",
    "        split = text.split(\" \")\n",
    "        lowered = [w.lower() for w in split]\n",
    "        if doStopWords:\n",
    "            if doPuncFilt:\n",
    "                word_list = [lm.lemmatize(word) for word in lowered if word not in stoplist and word.isalpha()]\n",
    "            else:\n",
    "                word_list = [lm.lemmatize(word) for word in lowered if word not in stoplist]\n",
    "        else:\n",
    "            if doPuncFilt:\n",
    "                word_list = [lm.lemmatize(word) for word in lowered if word.isalpha()]\n",
    "            else:\n",
    "                word_list = [lm.lemmatize(word) for word in lowered]\n",
    "    sentences=word_list\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def posTAGGING(text):\n",
    "    doc=nlp(text)\n",
    "    word_list=[]\n",
    "    for token in doc:\n",
    "        if token.pos_==\"ADJ\" or token.pos==\"ADV\":\n",
    "            word_list.append(token.text)\n",
    "    sentences=\" \".join(word_list)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f2a28",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "When considering the task intuitively the ideas that come into mind are to use words and length of review to analyse sentiment.\n",
    "\n",
    "However with lengh as a feature it doesn't work. With a Naive Bayes model it only got a 51% accuracy. Hence I decided with my current base model.\n",
    "\n",
    "With the baseline model I decided upon using individual words as the feature to look at. First by pre-processing and compiling all the words found in the positive and negative documents and labelling the them with their sentiment. How the labelled data are used will be explained later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2b89d",
   "metadata": {},
   "source": [
    "### Generate traning/test splits\n",
    "\n",
    "To take into account of generalization I decided to create 4 training/test splits with different random_states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9595a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"positive\"] * 2000 + [\"negative\"] * 2000\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data, labels, test_size=0.2, random_state=23)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(all_data, labels, test_size=0.2, random_state=42)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(all_data, labels, test_size=0.2, random_state=10)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(all_data, labels, test_size=0.2, random_state=24)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(all_data, labels, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ceae93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuple with 1st element as the featured words\n",
    "#2nd element is the sentiment\n",
    "train_list=[]\n",
    "test_list=[]\n",
    "def set_methods(doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt):\n",
    "    train_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_train]\n",
    "    test_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_test]\n",
    "    train2_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_train2]\n",
    "    test2_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_test2]\n",
    "    train3_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_train3]\n",
    "    test3_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_test3]\n",
    "    train4_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_train4]\n",
    "    test4_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_test4]\n",
    "    train5_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_train5]\n",
    "    test5_features = [(get_features_label(sents,doNothing,doStemma,doLemma,doTokenize,doStopWords,doPuncFilt), label) for (sents, label) in X_test5]\n",
    "    train_list.append(train_features)\n",
    "    train_list.append(train2_features)\n",
    "    train_list.append(train3_features)\n",
    "    train_list.append(train4_features)\n",
    "    train_list.append(train5_features)\n",
    "    test_list.append(test_features)\n",
    "    test_list.append(test2_features)\n",
    "    test_list.append(test3_features)\n",
    "    test_list.append(test4_features)\n",
    "    test_list.append(test5_features)\n",
    "#doNothing,           ,stem,lemm, token,stop,alpha\n",
    "set_methods(False    ,False,True,True,True,False)\n",
    "# print(f\"Element at index [0] of training set features: {train_list[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408de01c",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "\n",
    "Sanity check ensures that our train/test split has around equal split of negative and positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f477d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.493125\n",
      "0.4725\n",
      "0.495\n",
      "0.48\n",
      "0.5015625\n",
      "0.50625\n"
     ]
    }
   ],
   "source": [
    "def catProportions(data, cat):\n",
    "    count = 0\n",
    "    for item in data:\n",
    "        if item[1]==cat:\n",
    "            count += 1\n",
    "    return float(count) / float(len(data))\n",
    "print(catProportions(X_train,\"positive\"))\n",
    "print(catProportions(X_test,\"negative\"))\n",
    "print(catProportions(X_train2,\"positive\"))\n",
    "print(catProportions(X_test2,\"negative\"))\n",
    "print(catProportions(X_train3,\"positive\"))\n",
    "print(catProportions(X_test3,\"negative\"))\n",
    "print(catProportions(X_train4,\"positive\"))\n",
    "print(catProportions(X_test4,\"negative\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d10e2d",
   "metadata": {},
   "source": [
    "## Base implementation using Naive Bayes\n",
    "\n",
    "For the this implementation we will be using the NLTK's Naive Bayes classifier. Naive Bayes algorithm is based on the assumption that each feature is independent of one another, thus allowing predictions using only the probabilities of each individual feature. This is works with our task if we were to perform word association as the aglorthm assumes that each word is indepdent of each other thus it allows for predictions based on the probabilties of each word independently. This assumption leads to a more simple and efficient algorithm. More specifically the type of Naive Bayes used is a Multimodal Naive Bayes classifier. The difference between multimodel and other models it that they can incorporate different sources of data. A multimodal classifier can use data from multiple modalities while other types of naive Bayes classifiers can only use data from a single modality.\n",
    "\n",
    "\n",
    "Above is a figure describing how the probability is calculated:\n",
    "Consider the word amazing, to find the probability that amazing is in a positive review (amazing| Positive), we would need the determine the probablity of a positive review containing the word amazing(positive|amazing)  divided by the probability of a review being positive.\n",
    "This can also be seen as:\n",
    "P(amazing)|Positive) = (count of amazing in our data set) / (number of positive review)\n",
    "\n",
    "Now we perform that on every word we find and get their probabilities. We then multiply the probabilities of each word occurring in each class, and then compare the resulting probabilities to determine the class with the highest probability.\n",
    "\n",
    "Now that we have our pre-processing tools,selected feature vector and understaning of the classification algortihm we can now perform our sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f65d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size = 3200 reviews\n",
      "Testin set size = 800 reviews\n",
      "Accuracy on the training set 0 = 98.59375%\n",
      "Accuracy on the testing set 0 = 81.0%\n",
      "Accuracy on the training set 1 = 98.71875%\n",
      "Accuracy on the testing set 1 = 82.625%\n",
      "Accuracy on the training set 2 = 98.625%\n",
      "Accuracy on the testing set 2 = 83.375%\n",
      "Accuracy on the training set 3 = 98.5625%\n",
      "Accuracy on the testing set 3 = 82.5%\n",
      "Accuracy on the training set 4 = 98.4375%\n",
      "Accuracy on the testing set 4 = 81.0%\n",
      "Average accuracy: 98.5875\n",
      "Average accuracy: 82.1\n",
      "Most informative features within training and test set 5:\n",
      "Most Informative Features\n",
      "               laughable = True           negati : positi =     18.5 : 1.0\n",
      "                    7/10 = True           positi : negati =     15.1 : 1.0\n",
      "                   waste = True           negati : positi =     13.6 : 1.0\n",
      "                fabulous = True           positi : negati =     12.4 : 1.0\n",
      "              incoherent = True           negati : positi =     12.3 : 1.0\n",
      "            unbelievably = True           negati : positi =     12.3 : 1.0\n",
      "                    9/10 = True           positi : negati =     11.0 : 1.0\n",
      "                 boredom = True           negati : positi =     11.0 : 1.0\n",
      "                 miscast = True           negati : positi =     11.0 : 1.0\n",
      "                poignant = True           positi : negati =     10.4 : 1.0\n",
      "                    3/10 = True           negati : positi =     10.3 : 1.0\n",
      "              delightful = True           positi : negati =      9.9 : 1.0\n",
      "               atrocious = True           negati : positi =      9.8 : 1.0\n",
      "                 ashamed = True           negati : positi =      9.6 : 1.0\n",
      "             appreciated = True           positi : negati =      9.4 : 1.0\n",
      "               pointless = True           negati : positi =      9.3 : 1.0\n",
      "            embarrassing = True           negati : positi =      9.0 : 1.0\n",
      "                  shoddy = True           negati : positi =      9.0 : 1.0\n",
      "              friendship = True           positi : negati =      8.7 : 1.0\n",
      "           extraordinary = True           positi : negati =      8.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier, classify\n",
    "\n",
    "print (f\"Training set size = {str(len(X_train))} reviews\")\n",
    "print (f\"Testin set size = {str(len(X_test))} reviews\")\n",
    "# train the classifier\n",
    "count=0\n",
    "count2=0\n",
    "for i in range (5):\n",
    "    classifier = NaiveBayesClassifier.train(train_list[i])\n",
    "    training_accuracy=classify.accuracy(classifier, train_list[i])*100\n",
    "    count+=training_accuracy\n",
    "    testing_accuracy=classify.accuracy(classifier, test_list[i])*100\n",
    "    count2+=testing_accuracy\n",
    "    print (f\"Accuracy on the training set {i} = {training_accuracy}%\")   \n",
    "    print (f\"Accuracy on the testing set {i} = {testing_accuracy}%\")\n",
    "\n",
    "##to identify generalability\n",
    "print(f\"Average accuracy: {count/5}\")\n",
    "print(f\"Average accuracy: {count2/5}\")\n",
    "# check which words are most informative for the classifier\n",
    "print(\"Most informative features within training and test set 5:\")\n",
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ca7f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[334  63]\n",
      " [ 89 314]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# predicted labels\n",
    "y_pred = classifier.classify_many([fs for (fs, l) in test_list[4]])\n",
    "\n",
    "# actual labels\n",
    "y_true = [label for (sentence, label) in test_list[4]]\n",
    "\n",
    "# generate confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(confusion_matrix)\n",
    "\n",
    "# display confusion matrix\n",
    "plt.imshow(confusion_matrix, cmap='Blues')\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add labels\n",
    "labels=[\"positive\",\"negative\"]\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "\n",
    "# add title and axis labels\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c7e98",
   "metadata": {},
   "source": [
    "| Stemmatise | Lemmatise |  Tokenization | Stopwords | AlphaNumericOnly| Average Training Accuracy |Average Testing Accuracy|\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: | :-:|\n",
    "|False | False | False| False| False | 99.44%  |80.75%|\n",
    "|False | False | True | False | False | 97.88% |81.3%|\n",
    "|False | False | False| True | True  | 98.12% |80.95%|\n",
    "|False | False | True | True | True  | 98.22% |81.85% |\n",
    "|False | False | True | True | False | 98.74% |82.15%|\n",
    "|False | True  | True | True | False | 98.44% |82.1%|\n",
    "|False | True  | True | False | False  |97.61% |81.25%|\n",
    "|False | True  | False | False | False  |99.27% |81.5%|\n",
    "|False | True  | True | True | True  |97.88% |82.45%|\n",
    "|True | False  | True | True | True  |96.34% |82.05%|\n",
    "|True | False  | True | False | False  |96.67% |80.8%|\n",
    "|True | False  | True | True | False  |97.51% |82.25%|\n",
    "|True | False  | False | False | False  |99.10% |81.4%|\n",
    "|True | False  | True | False | True  |95.50% |81.75%|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f172e0a",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "By adjusting the different pre-processing steps our accuracies change. Looking at the table you can see the different combinations of pre-processing steps and the corresponding average accuracies over 5 training/test splits. The highest accuracy obtained in 82.45%.\n",
    "#### No pre-processing\n",
    "Without any pre-processing at all and splitting the words through whitespaces we obtained an average score of 80.75%. \n",
    "#### Tokenization\n",
    "With only the use of tokenization we gained an increase to 81.3%. Tokenization can improve the accuracy as it may remove punctuations. For example by removing punctuations, you can prevent a review with a lot of exclamation points from being wrongly classified as highly negative or positive.\n",
    "\n",
    "#### Stopwords\n",
    "Stop words do not contain any useful information that the model can use to make predictions. By removing stop words, you can reduce the amount of noise in the text, which can help the model make more accurate predictions. This is shown when the probability increases to 81.3%.\n",
    "\n",
    "#### Focussing only on strings containing alphabets\n",
    "You can see that when we only filter alphabets the number of accuracy decreases. This is because within reviews, there are sometimes ratings \"7/10\" that are written which many of the 7 rating reviews have and is one of the top 20 most informative features for being positive.\n",
    "\n",
    "#### Stemmatise\n",
    "Stemmatization is the process of reducing words to their base forms. For exaple words like \"good\", \"better\", and \"best\", reduce to \"good\". This reduces the amount of noise within our feature set which can increase accuracy as seen below.\n",
    "#### Lemmatise\n",
    "Consider the same example as above \"good\", \"better\", and \"best\", lemmatization reduces these to \"good\" when used in comparision, but unlike stemmatization it would reduce \"best\" to the lemma \"well\" when used as an adverb. This would allow us to treat these words as if they were the same word, while still holds it own nuance. This performed better than Stemmatisation. Lemmatization coupled with teoknization and removal of stopwards had the greater increase in testing accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c92b8",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "What has been understood from the matrix is that 97 negative reviews were tagged positive while 58 positive reviews were tagged negative. This would mean that there are certain words that are used alot in negative reviews that overlapped. This could be due to the point the idea of sarcasm and irony. Sarcasm and irony is scattered throughout negative reviews. This could also indicate how we use our language. This data could potentially mean that we tend to use more sarcasm and irony when we feel a negative way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2c0e3",
   "metadata": {},
   "source": [
    "### Most informative features\n",
    "When we don't filter out strings that contains strings not only with alphabets. Few things can be seen when analyzing the most informative features. The model seems to like the fraction numbers as identifiers. However it does not seem to be the case when I filter strings to only contains alphabets the prediction accuracy goes up. This mean that the model has less words to use and identifers but the reduce of noise causes the increase in accuracy. Many of the words seen were surprising to see as they typically aren't sentimental however our model picks up on these. There may be sentimental correlations to the words that I might not know of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4fd4d",
   "metadata": {},
   "source": [
    "Now we will try using a TF-IDF instead with a Naive Bayes Classifier.\n",
    "This time we will be using a sklearn's Multimodal Naive Bayes classifier as it allows tfidf values vectors to be passed in.\n",
    "## TF-IDF\n",
    "TF-IDF is a weighted model that represents the importance of a word in a document by its frequency within that document and its frequency across all documents.\n",
    "\n",
    "The TfidfVectorizer converts the text into numerical representations (feature vectors). When you apply the TfidfVectorizer to an input review, it will first tokenize the review into individual words and then compute the term-frequency-inverse-document-frequency (TF-IDF) value for each word.\n",
    "\n",
    "The term-frequency is a measure of how often an item appears in the review, while the inverse-document-frequency is a measure importance to of an item to particular document. The TF-IDF is calculated by the product of term-frequency and inverse-document-frequency, and it is used to weigh the importance of each token in the review.\n",
    "\n",
    "The range of TF-IDF scores are from 0-1 with 1 being most important and 0 the least. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecabdd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "labels = [\"positive\"] * 2000 + [\"negative\"] * 2000\n",
    "processed=[]\n",
    "vectorizer = TfidfVectorizer()\n",
    "for items in all_data:\n",
    "    textF=get_features_lemma(items[0],True,True,True)\n",
    "#     textF=get_features_stemma(items[0],True,True,True)\n",
    "    textF=\" \".join(textF)\n",
    "    processed.append(textF)\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed, labels, test_size=0.2, random_state=23)#23\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(all_data, labels, test_size=0.2, random_state=42)\n",
    "# X_train3, X_test3, y_train3, y_test3 = train_test_split(all_data, labels, test_size=0.2, random_state=10)\n",
    "# X_train4, X_test4, y_train4, y_test4 = train_test_split(all_data, labels, test_size=0.2, random_state=24)\n",
    "# X_train5, X_test5, y_train5, y_test5 = train_test_split(all_data, labels, test_size=0.2, random_state=7)\n",
    "X_train_vector1 = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data with the fitted vectorizer\n",
    "X_test_vector1 = vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a MultinomialNB object\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train_vector1, y_train)\n",
    "\n",
    "# Use the trained classifier to make predictions on the testing data\n",
    "y_pred = clf.predict(X_test_vector1)\n",
    "\n",
    "# Evaluate the classifier's performance on the testing data\n",
    "accuracy = clf.score(X_test_vector1, y_test)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c232e004",
   "metadata": {},
   "source": [
    "| Stemmatise | Lemmatise |  Tokenization | Stopwords | AlphaNumericOnly| Average Testing Accuracy|\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "|False | False | False| False| False | 81.44%|\n",
    "|False | True  | True | True | False | 82.63%|\n",
    "|False | True  | True | True | True | 82.80%|\n",
    "|True | False  | True | True | True | 82.08%|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7a03f",
   "metadata": {},
   "source": [
    "## Second interation: TF-IDF with a Naive Bayes classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1efc2ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'positive']\n",
      "Top 10 features for positive:\n",
      "\tpeople\n",
      "\tbest\n",
      "\tmake\n",
      "\tlife\n",
      "\twould\n",
      "\tlove\n",
      "\talso\n",
      "\twell\n",
      "\treally\n",
      "\tshow\n",
      "\tcharacter\n",
      "\tsee\n",
      "\ttime\n",
      "\tgood\n",
      "\tlike\n",
      "\tstory\n",
      "\tgreat\n",
      "\tone\n",
      "\tmovie\n",
      "\tfilm\n",
      "Top 10 features for negative:\n",
      "\tfulton\n",
      "\tintellectually\n",
      "\tintellectualize\n",
      "\tconsequently\n",
      "\tconsequent\n",
      "\tpochath\n",
      "\tconsented\n",
      "\tpocus\n",
      "\teu\n",
      "\tconsensual\n",
      "\tpoesy\n",
      "\tconscripted\n",
      "\tpoetical\n",
      "\tconsciously\n",
      "\tconscientious\n",
      "\tpointlessly\n",
      "\tpointlessness\n",
      "\tpointlessthe\n",
      "\tconquistador\n",
      "\tpointy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonlim/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/simonlim/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Get the names of the features\n",
    "feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "\n",
    "# Get the names of the labels\n",
    "label_names = clf.classes_\n",
    "print(label_names)\n",
    "# Print the features and their corresponding labels\n",
    "top_features = np.argsort(clf.coef_[0])[-20:]\n",
    "print(f'Top 10 features for {label_names[1]}:')\n",
    "for feature_index in top_features:\n",
    "    print(f'\\t{feature_names[feature_index]}')\n",
    "    \n",
    "top_features = np.argsort(clf.coef_[0])[:20]\n",
    "print(f'Top 10 features for {label_names[0]}:')\n",
    "for feature_index in top_features:\n",
    "    print(f'\\t{feature_names[feature_index]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db5a93d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.88      0.84       400\n",
      "    positive       0.86      0.78      0.82       400\n",
      "\n",
      "    accuracy                           0.83       800\n",
      "   macro avg       0.83      0.83      0.83       800\n",
      "weighted avg       0.83      0.83      0.83       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7bc1409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[351  49]\n",
      " [ 87 313]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use the trained classifier to make predictions on the testing data\n",
    "y_pred = clf.predict(X_test_vector1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix)\n",
    "plt.imshow(confusion_matrix, cmap='Blues')\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add labels\n",
    "labels=[\"positive\",\"negative\"]\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "\n",
    "# add title and axis labels\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b196c6",
   "metadata": {},
   "source": [
    "| Stemmatise | Lemmatise |  Tokenization | Stopwords | AlphaNumericOnly| Average Testing Accuracy|\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "|False | False | False| False| False | 81.44%|\n",
    "|False | True  | True | True | False | 82.63%|\n",
    "|False | True  | True | True | True | 82.80%|\n",
    "|True | False  | True | True | True | 82.08%|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093b1854",
   "metadata": {},
   "source": [
    "## Second interation results analysis\n",
    "Again you can see after altering the pre-processing techniques Lemmatization with tokenization seems to be working well with TF-IDF Naive Bayes. When only keeping strings that contains only alphabets the TF-IDF system really likes it. There isn't much of an increase in 0.4% from the best pre-processing obtained from the base implementaion. The confusion matrix is similar when we did our base implementation where there are more negative reviews still tagged as positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4f1cd",
   "metadata": {},
   "source": [
    "## Final interation: TF-IDF with Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e356c2",
   "metadata": {},
   "source": [
    "A linear support vector classifier (SVC) is a support vector machine that is trained to perform classification tasks using a linear kernel. It is linear model that can be used to separate data points into two classes by finding a line that best divides the data into the desired classes.\n",
    "Linear SVCs have several advantages over other classification methods. They are fast and efficient to train, even on large datasets, and they can handle high-dimensional data well. Linear SVC's are also relatively insensitive to overfitting, which means that they can generalize well to new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5d835a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "labels = [\"positive\"] * 2000 + [\"negative\"] * 2000\n",
    "vectorizer = TfidfVectorizer()\n",
    "processed=[]\n",
    "for items in all_data:\n",
    "#     textF=get_features_stemma(items[0],False,False,False)\n",
    "    textF=get_features_lemma(items[0],True,False,False)\n",
    "    textF=\" \".join(textF)\n",
    "    processed.append(textF)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(processed, labels, test_size=0.2, random_state=10)#23\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(all_data, labels, test_size=0.2, random_state=42)#42\n",
    "# X_train3, X_test3, y_train3, y_test3 = train_test_split(all_data, labels, test_size=0.2, random_state=10)#10\n",
    "# X_train4, X_test4, y_train4, y_test4 = train_test_split(all_data, labels, test_size=0.2, random_state=24)#24\n",
    "# X_train5, X_test5, y_train5, y_test5 = train_test_split(all_data, labels, test_size=0.2, random_state=7)#7\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data with the fitted vectorizer\n",
    "X_test = vectorizer.transform(X_test)\n",
    "# Create and train the SVM model\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy*100)\n",
    "# Create the TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e032097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'positive']\n",
      "Top 10 features for positive:\n",
      "\tperfect\n",
      "\tbest\n",
      "\trecommended\n",
      "\tworld\n",
      "\twonderful\n",
      "\twell\n",
      "\tfavorite\n",
      "\tliked\n",
      "\texcellent\n",
      "\tgreat\n",
      "Top 10 features for negative:\n",
      "\tbad\n",
      "\tworst\n",
      "\twaste\n",
      "\tawful\n",
      "\tpoor\n",
      "\tno\n",
      "\tscript\n",
      "\tterrible\n",
      "\tunfortunately\n",
      "\tdull\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonlim/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Get the names of the features\n",
    "feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "\n",
    "# Get the names of the labels\n",
    "label_names = model.classes_\n",
    "print(label_names)\n",
    "# Print the features and their corresponding labels\n",
    "top_features = np.argsort(model.coef_[0])[-10:]\n",
    "print(f'Top 10 features for {label_names[1]}:')\n",
    "for feature_index in top_features:\n",
    "    print(f'\\t{feature_names[feature_index]}')\n",
    "    \n",
    "top_features = np.argsort(model.coef_[0])[:10]\n",
    "print(f'Top 10 features for {label_names[0]}:')\n",
    "for feature_index in top_features:\n",
    "    print(f'\\t{feature_names[feature_index]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "269dd16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.56      0.52       384\n",
      "    positive       0.53      0.46      0.50       416\n",
      "\n",
      "    accuracy                           0.51       800\n",
      "   macro avg       0.51      0.51      0.51       800\n",
      "weighted avg       0.51      0.51      0.51       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba6dc9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.0\n",
      "[[320  64]\n",
      " [ 64 352]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "true_labels = y_test\n",
    "\n",
    "# predicted labels for the test data\n",
    "predicted_labels = predictions\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(accuracy*100)\n",
    "print(cm)\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add labels\n",
    "labels=[\"positive\",\"negative\"]\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "\n",
    "# add title and axis labels\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be99a4e",
   "metadata": {},
   "source": [
    "|Stemmatise | Lemmatise |  Tokenization | Stopwords | AlphaNumericOnly| Average Testing Accuracy|\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "|False | False | False| False| False | 85.28%|\n",
    "|False | True | False| False| False | 85.28%|\n",
    "|False | True | False| False| True | 82.75%|\n",
    "|False | True  | True | False | False | 84.66%|\n",
    "|False | True  | True | True | False | 84.43%|\n",
    "|False | True  | True | True | True | 84.68%|\n",
    "|True | False  | True | True | True | 84.00%|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b70ca",
   "metadata": {},
   "source": [
    "## Review of TF-IDF with a linear SVC\n",
    "\n",
    "Linear SVC performs 2.48% better than TF-IDF with Naive Bayes. Interestingly the accuracy between Lemmatized and not Lemmatized without any other pre-processing technique scored the same. However, during my test I noticed a wider range of generalization with lemmatized text. This model also works best without any pre-processing. More specific pre-processing may lead to better performace for this model. Looking at the confusion matrix, the mistakes being made by this model is less skewed to false positives and is more equal. The top 10 features for positives/negatives shown are also very obvious to me that they have their respective sentiment (brilliant, great, bad, waste, etc...). No fractions are seen in the top 10 features anymore as well hence the importance of them may be insiginificant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04fe35c3",
   "metadata": {},
   "source": [
    "## Parsing and chunking with our final model\n",
    "This section I decided to apply the parsing and chunking on my final model. This is due to the intuition that words like adjectives and adverbs are often important for expressing sentiment, as they are used to describe the qualities or emotions associated with a noun or verb. Hence, I decided to perform two task,1) only take Adverbs, nouns, adjectives and verbs and 2) take only adverbs and adjectives. Then pre-process those words and train our model. This can be done by Parts of Speech tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71219699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "labels = [\"positive\"] * 2000 + [\"negative\"] * 2000\n",
    "vectorizer = TfidfVectorizer()\n",
    "processed=[]\n",
    "for items in all_data:\n",
    "    postagged=posTAGGING(items[0])\n",
    "#     textF=get_features_stemma(items[0],False,False,False)\n",
    "    textF=get_features_lemma(postagged,True,False,False)\n",
    "    textF=\" \".join(textF)\n",
    "    processed.append(textF)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(processed, labels, test_size=0.2, random_state=7)#23\n",
    "# X_train2, X_test2, y_train2, y_test2 = train_test_split(all_data, labels, test_size=0.2, random_state=42)#42\n",
    "# X_train3, X_test3, y_train3, y_test3 = train_test_split(all_data, labels, test_size=0.2, random_state=10)#10\n",
    "# X_train4, X_test4, y_train4, y_test4 = train_test_split(all_data, labels, test_size=0.2, random_state=24)#24\n",
    "# X_train5, X_test5, y_train5, y_test5 = train_test_split(all_data, labels, test_size=0.2, random_state=7)#7\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data with the fitted vectorizer\n",
    "X_test = vectorizer.transform(X_test)\n",
    "# Create and train the SVM model\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy*100)\n",
    "# Create the TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1467725",
   "metadata": {},
   "source": [
    "#### ADVERBS+NOUNS+VERBS+ADJECTIVES\n",
    "|Stemmatise | Lemmatise |  Tokenization | Stopwords | AlphaNumericOnly| Average Testing Accuracy|\n",
    "| :-: | :-: | :-: | :-: | :-: |:-: |\n",
    "|False | True | False| False| False | 79.69%|\n",
    "#### ADVERBS+ADJECTIVES\n",
    "|Stemmatise | Lemmatise |  Tokenization | Stopwords | AlphaNumericOnly| Average Testing Accuracy|\n",
    "| :-: | :-: | :-: | :-: | :-: |:-: |\n",
    "|False | True | False| False| False | 78.63%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Get the names of the features\n",
    "feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "\n",
    "# Get the names of the labels\n",
    "label_names = model.classes_\n",
    "print(label_names)\n",
    "# Print the features and their corresponding labels\n",
    "top_features = np.argsort(model.coef_[0])[-10:]\n",
    "print(f'Top 10 features for {label_names[1]}:')\n",
    "for feature_index in top_features:\n",
    "    print(f'\\t{feature_names[feature_index]}')\n",
    "    \n",
    "top_features = np.argsort(model.coef_[0])[:10]\n",
    "print(f'Top 10 features for {label_names[0]}:')\n",
    "for feature_index in top_features:\n",
    "    print(f'\\t{feature_names[feature_index]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "true_labels = y_test\n",
    "\n",
    "# predicted labels for the test data\n",
    "predicted_labels = predictions\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(accuracy*100)\n",
    "print(cm)\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "\n",
    "# add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# add labels\n",
    "labels=[\"positive\",\"negative\"]\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "\n",
    "# add title and axis labels\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8bc59",
   "metadata": {},
   "source": [
    "#### ADVERBS+NOUNS+VERBS+ADJECTIVES\n",
    "|Stemmatise | Lemmatise |  Tokenization | Stopwords | AlphaNumericOnly| Average Testing Accuracy|\n",
    "| :-: | :-: | :-: | :-: | :-: |:-: |\n",
    "|False | True | False| False| False | 79.69%|\n",
    "\n",
    "#### ADVERBS+ADJECTIVES\n",
    "|Stemmatise | Lemmatise |  Tokenization | Stopwords | AlphaNumericOnly| Average Testing Accuracy|\n",
    "| :-: | :-: | :-: | :-: | :-: |:-: |\n",
    "|False | True | False| False| False | 78.63%|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc639a8",
   "metadata": {},
   "source": [
    "Looking at the accuracy it would appear that the model works worse with the POS filter. This proves that context matters within parts of speech and filtering out words that do not fall under adverbs, adjectives, nouns and verbs will lose some of its sentiment. The top 10 features of positives and negatives do display only adjectives+adverbs as per expected. Confusion matrix is has more wrong tagging for true positive sentiments but overall nothing out of the ordinary. From this data it proves that chunking and parsing requires very intriciate techniques to maintain the nuance of reviews to better analyse sentiment and using them just to filter certain parts of speech does not necessarily improve a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b562445f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "From starting with the Base Naive Bayes and using word probablities I ended with TF-IDF on a linearSVC classifier with pre-processed text.\n",
    "\n",
    "Pre-processing has a lot to play in terms of Sentiment Analysis, drastic changes can occur when done properly. Chunking and parsing was done through Parts of Speech tagging however the results were not the best as there were no improvements.\n",
    "\n",
    "Given more time I would definitely try and look into recurrent neural networks as I have read that it can be used for sentiment analysis. Another area which I would like to look into optimizing the use of chunking and parsing using parts of speech as that is an area of interest of mine.\n",
    "\n",
    "Groundbreaking development like BERT has come a long way interms of NLP and this project has defintely gave me a glimpse of its difficuly and how to approach an NLP task througouhly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
